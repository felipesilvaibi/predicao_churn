{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML FLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/27 22:42:12 INFO mlflow.tracking.fluent: Experiment with name 'Churn Prediction' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/felipe/dev/predicao_churn/src/mlruns/1', experiment_id='1', lifecycle_stage='active', name='Churn Prediction', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cria o experimento (mlflow)\n",
    "mlflow.set_experiment('Churn Prediction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('../data/carteira_total.feather')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correção da nomenclatura das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "newColumnsName = []\n",
    "for column_name in df:\n",
    "  newColumnsName.append(\n",
    "      re.sub('[^A-Za-z0-9]+', '_', unidecode(column_name).lower()))\n",
    "df.columns = newColumnsName\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da variável target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"upsale_downsale\"].replace(\n",
    "    {\"Churn\": \"churn\", \"Upsell\": \"upsell\", \"Downsell\": \"downsell\", \"Ok\": \"ok\"}, inplace=True)\n",
    "df['churn'] = df['upsale_downsale']\n",
    "df['churn'].replace(\n",
    "    {\"ok\": \"0\", \"upsell\": \"0\", \"downsell\": \"0\", \"churn\": \"1\"}, inplace=True)\n",
    "\n",
    "df.drop(columns=[\"upsale_downsale\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da variável \"quantidades mês\" (feature engeneering com a variável nativa \"mês\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df[['mes', 'id_sap']].groupby(['id_sap']).count().reset_index()\n",
    "\n",
    "df_grouped.rename(columns = {'mes':'quantidade_mes'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df_grouped.set_index('id_sap'), on='id_sap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da variável \"status_pagamento\" (feature engeneering utilizando fonte de dados externa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('../data/quality_score.xlsx')\n",
    "xls.sheet_names\n",
    "\n",
    "i = 0\n",
    "for data in xls.sheet_names:\n",
    "    if i == 0:\n",
    "        dfQuality = pd.read_excel(xls, data)\n",
    "        dfQuality['data'] = data\n",
    "        dfQuality.rename(columns={'Classificação Pagamento': 'status_pagamento', 'Quality Score Cobrança': 'status_pagamento',\n",
    "                                  'PFIN': 'status_pagamento', 'PEFIN': 'status_pagamento'}, inplace=True)\n",
    "    else:\n",
    "        dfQualityAux = pd.read_excel(xls, data)\n",
    "        dfQualityAux['data'] = data\n",
    "        dfQualityAux.rename(columns={'Classificação Pagamento': 'status_pagamento', 'Quality Score Cobrança': 'status_pagamento',\n",
    "                                     'PFIN': 'status_pagamento', 'PEFIN': 'status_pagamento'}, inplace=True)\n",
    "\n",
    "        dfQuality = pd.concat([dfQuality, dfQualityAux])\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQuality['status_pagamento'].replace({'4. Péssimo': 'Pessimo', '2. Regular ': 'Regular', '1. Bom': 'Bom', '3. Ruim': 'Ruim', '5. Novo': 'Novo',\n",
    "                                       '2. Regular': 'Regular', '1. Bom ': 'Bom', 'lançamentos': np.nan, '5. novo': 'Novo', 0: np.nan}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQuality.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'([0-9]{4})-([0-9]{2})-[0-9]{2}'\n",
    "\n",
    "\n",
    "def fun_replace(data):\n",
    "    return datetime.datetime.strptime(str(data.group(2)).lower(), '%m').strftime('%b').lower() + data.group(1)[-2:]\n",
    "\n",
    "\n",
    "df['mes'] = df['mes'].astype(str).str.replace(regex, fun_replace, regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQuality.rename(columns={'ID SAP': 'id_sap', 'data': 'mes'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(dfQuality.set_index(['id_sap', 'mes']), on=['id_sap', 'mes'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correção dos valores de colunas categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['oficina'].replace({'wi': 'WI'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['frequencia_de_faturamento'] = df['frequencia_de_faturamento'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['frequencia_de_faturamento'] = df['frequencia_de_faturamento'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['frequencia_de_faturamento'].replace(\n",
    "    {'única vez': 'unica_vez'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['equipe'].replace({'Relacionamento': 'RELACIONAMENTO', 'Jumbo': 'JUMBO',\n",
    "                     'Resellers': 'RESELLERS', 'Regional DF': 'REGIONAL DF'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop de colunas com valores inutilizáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['contratado_freemium', 'utilizado_freemium'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção das colunas mais significativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['pf_pj', 'contratado_ofertas_simples', 'utilizado_ofertas_simples',\n",
    "         'leads_form', 'equipe', 'utilizado_destaque', 'valor_mensal',\n",
    "         'quantidade_mes', 'status_pagamento', 'churn', 'regiao', 'oficina', 'tipo_de_plano', 'frequencia_de_faturamento']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop dos registros cujo o status de pagamento é nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['status_pagamento'].notna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "feature = ['pf_pj', 'equipe', 'status_pagamento', 'regiao',\n",
    "           'oficina', 'tipo_de_plano', 'frequencia_de_faturamento']\n",
    "\n",
    "enc.fit(df[feature])\n",
    "\n",
    "## Registro do encoder\n",
    "mlflow.sklearn.log_model(enc, 'one_hot_encoder')\n",
    "\n",
    "ohe_feature = enc.transform(df[feature]).toarray()\n",
    "df_ohe = pd.DataFrame(\n",
    "    ohe_feature, columns=enc.get_feature_names(feature))\n",
    "\n",
    "df_ohe.index = df.index\n",
    "df = pd.concat([df, df_ohe], axis=1)\n",
    "\n",
    "df = df.drop(columns=feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "imputer.fit(df)\n",
    "\n",
    "## Registro do imputer\n",
    "mlflow.sklearn.log_model(imputer, 'imputer')\n",
    "\n",
    "df = pd.DataFrame(imputer.transform(df), columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['churn'], axis=1)\n",
    "y = df['churn'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=X_train.columns)\n",
    "y_train = pd.Series(y_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=1)  # 0.25 x 0.8 = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de dados numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trataDados(df_dados, target):\n",
    "    # Balanceamento dos dados\n",
    "    sm = SMOTE(sampling_strategy='minority', random_state=7)\n",
    "    df_dados, target = sm.fit_resample(df_dados, target.filter(df_dados.index))\n",
    "\n",
    "    # Normalização dos dados\n",
    "    numericalColumns = ['contratado_ofertas_simples', 'utilizado_ofertas_simples', 'leads_form',\n",
    "                        'utilizado_destaque', 'valor_mensal', 'quantidade_mes']\n",
    "    scaler = RobustScaler().fit(df_dados[numericalColumns])\n",
    "    df_dados[numericalColumns] = scaler.transform(df_dados[numericalColumns])\n",
    "\n",
    "    ## Registro do scaler\n",
    "    mlflow.sklearn.log_model(scaler, 'scaler')\n",
    "\n",
    "    return df_dados, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['status_pagamento'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_features = ['contratado_ofertas_simples', 'utilizado_ofertas_simples', 'leads_form', 'utilizado_destaque', 'valor_mensal', 'quantidade_mes']\n",
    "# numeric_transformer = Pipeline(\n",
    "#     steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    "# )\n",
    "\n",
    "# categorical_features = ['pf_pj', 'equipe', 'status_pagamento', 'regiao', 'oficina', 'tipo_de_plano', 'frequencia_de_faturamento']\n",
    "# categorical_transformer = OneHotEncoder()\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         (\"num\", numeric_transformer, numeric_features),\n",
    "#         (\"cat\", categorical_transformer, categorical_features),\n",
    "#     ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_features = ['contratado_ofertas_simples', 'utilizado_ofertas_simples',\n",
    "#                     'leads_form', 'utilizado_destaque', 'valor_mensal', 'quantidade_mes']\n",
    "# numeric_transformer = Pipeline(\n",
    "#     steps=[('scaler', RobustScaler())]\n",
    "# )\n",
    "\n",
    "# posprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         (\"num\", numeric_transformer, numeric_features),\n",
    "#     ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = Pipeline(\n",
    "#     steps=[\n",
    "#         # (\"preprocessor\", preprocessor),\n",
    "#         ('sampling', SMOTE(sampling_strategy='minority', random_state=0)),\n",
    "#         (\"posprocessor\", posprocessor),\n",
    "#            (\"classifier\", MLPClassifier(hidden_layer_sizes=(6, 5),\n",
    "#                                          random_state=1,\n",
    "#                                          verbose=True,\n",
    "#                                          learning_rate_init=0.01))]\n",
    "# )\n",
    "\n",
    "# X = df.drop(['churn'], axis=1)\n",
    "# y = df['churn'].astype(int)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "# predictDataSet = clf.predict(X_test)\n",
    "\n",
    "# f1 = round(f1_score(y_test, y_pred, average='macro')*100, 2)\n",
    "# accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "# precision = round(precision_score(y_test, predictDataSet)*100, 2)\n",
    "# recall = round(recall_score(y_test, predictDataSet)*100, 2)\n",
    "\n",
    "# print(f\"F1 Score: {f1}%\")\n",
    "# print(f\"Accuracy Score: {accuracy}%\")\n",
    "# print(f\"Precision Score: {precision}%\")\n",
    "# print(f\"Recall Score: {recall}%\")\n",
    "\n",
    "# plot_confusion_matrix(clf, X_test, y_test, display_labels=[\n",
    "#     \"positivo\", \"negativo\"], values_format=\"d\")\n",
    "# plt.grid(False)\n",
    "# plt.show()\n",
    "\n",
    "# plot_roc_curve(clf, X_test, y_test)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = trataDados(X_train, y_train)\n",
    "X_val, y_val = trataDados(X_val, y_val)\n",
    "X_test, y_test = trataDados(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeModel(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y=y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1 = round(f1_score(y_test, y_pred, average='macro')*100, 2)\n",
    "    accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "    precision = round(precision_score(y_test, y_pred)*100, 2)\n",
    "    recall = round(recall_score(y_test, y_pred)*100, 2)\n",
    "\n",
    "    ## Registro de métricas (mlflow)\n",
    "    mlflow.log_metric(\"_f1\", f1)\n",
    "    mlflow.log_metric(\"_accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"_precision\", precision)\n",
    "    mlflow.log_metric(\"_recall\", recall)\n",
    "\n",
    "    ## Registro da signature e do pipeline (mlflow)\n",
    "    signature = infer_signature(X_test, y_pred)\n",
    "    mlflow.sklearn.log_model(model, 'model_pipeline', signature=signature)\n",
    "    params = model.get_params()\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    print(f\"F1 Score: {f1}%\")\n",
    "    print(f\"Accuracy Score: {accuracy}%\")\n",
    "    print(f\"Precision Score: {precision}%\")\n",
    "    print(f\"Recall Score: {recall}%\")\n",
    "\n",
    "    plot_confusion_matrix(model, X_test, y_test, display_labels=[\n",
    "        \"positivo\", \"negativo\"], values_format=\"d\")\n",
    "        \n",
    "    ## Registro de Artefato confusion matrix (mlflow)\n",
    "    plt.savefig(\"mlruns/confusion_matrix_.png\")\n",
    "    mlflow.log_artifact(\"mlruns/confusion_matrix_.png\")\n",
    "    plt.close()\n",
    "\n",
    "    ## Registro de Artefato curva roc (mlflow)\n",
    "    plt.savefig(\"mlruns/roc_curve_.png\")\n",
    "    mlflow.log_artifact(\"mlruns/roc_curve_.png\")\n",
    "    plt.close()\n",
    "\n",
    "    ## Finalização da execução (mlflow)\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron\n",
      "------------------------------\n",
      "F1 Score: 87.29%\n",
      "Accuracy Score: 87.29%\n",
      "Precision Score: 87.31%\n",
      "Recall Score: 87.26%\n"
     ]
    }
   ],
   "source": [
    "print('Multilayer Perceptron')\n",
    "print('-' * 30)\n",
    "executeModel(MLPClassifier(hidden_layer_sizes=(6, 5),\n",
    "                           random_state=42,\n",
    "                           learning_rate_init=0.01), X_train, y_train, X_val, y_val)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60683c818ea6f768f811ad5f90736ebd9ed15f5ee0114937570dcd60c186bf40"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
