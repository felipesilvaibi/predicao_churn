{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('../data/carteira_total.feather')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correção da nomenclatura das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "newColumnsName = []\n",
    "for column_name in df:\n",
    "  newColumnsName.append(\n",
    "      re.sub('[^A-Za-z0-9]+', '_', unidecode(column_name).lower()))\n",
    "df.columns = newColumnsName\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da variável target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"upsale_downsale\"].replace(\n",
    "    {\"Churn\": \"churn\", \"Upsell\": \"upsell\", \"Downsell\": \"downsell\", \"Ok\": \"ok\"}, inplace=True)\n",
    "df['churn'] = df['upsale_downsale']\n",
    "df['churn'].replace(\n",
    "    {\"ok\": \"0\", \"upsell\": \"0\", \"downsell\": \"0\", \"churn\": \"1\"}, inplace=True)\n",
    "\n",
    "df.drop(columns=[\"upsale_downsale\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da variável \"quantidades mês\" (feature engeneering com a variável nativa \"mês\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df[['mes', 'id_sap']].groupby(['id_sap']).count().reset_index()\n",
    "\n",
    "df_grouped.rename(columns = {'mes':'quantidade_mes'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df_grouped.set_index('id_sap'), on='id_sap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da variável \"status_pagamento\" (feature engeneering utilizando fonte de dados externa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('../data/quality_score.xlsx')\n",
    "xls.sheet_names\n",
    "\n",
    "i = 0\n",
    "for data in xls.sheet_names:\n",
    "    if i == 0:\n",
    "        dfQuality = pd.read_excel(xls, data)\n",
    "        dfQuality['data'] = data\n",
    "        dfQuality.rename(columns={'Classificação Pagamento': 'status_pagamento', 'Quality Score Cobrança': 'status_pagamento',\n",
    "                                  'PFIN': 'status_pagamento', 'PEFIN': 'status_pagamento'}, inplace=True)\n",
    "    else:\n",
    "        dfQualityAux = pd.read_excel(xls, data)\n",
    "        dfQualityAux['data'] = data\n",
    "        dfQualityAux.rename(columns={'Classificação Pagamento': 'status_pagamento', 'Quality Score Cobrança': 'status_pagamento',\n",
    "                                     'PFIN': 'status_pagamento', 'PEFIN': 'status_pagamento'}, inplace=True)\n",
    "\n",
    "        dfQuality = pd.concat([dfQuality, dfQualityAux])\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQuality['status_pagamento'].replace({'4. Péssimo': 'Pessimo', '2. Regular ': 'Regular', '1. Bom': 'Bom', '3. Ruim': 'Ruim', '5. Novo': 'Novo',\n",
    "                                       '2. Regular': 'Regular', '1. Bom ': 'Bom', 'lançamentos': np.nan, '5. novo': 'Novo', 0: np.nan}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQuality.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'([0-9]{4})-([0-9]{2})-[0-9]{2}'\n",
    "\n",
    "\n",
    "def fun_replace(data):\n",
    "    return datetime.datetime.strptime(str(data.group(2)).lower(), '%m').strftime('%b').lower() + data.group(1)[-2:]\n",
    "\n",
    "\n",
    "df['mes'] = df['mes'].astype(str).str.replace(regex, fun_replace, regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQuality.rename(columns={'ID SAP': 'id_sap', 'data': 'mes'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(dfQuality.set_index(['id_sap', 'mes']), on=['id_sap', 'mes'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correção dos valores de colunas categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.select_dtypes(include=['object']):\n",
    "    df[column] = df[column].apply(lambda x: re.sub(\n",
    "        '[^A-Za-z0-9]+', '_', unidecode(x).lower()) if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção das colunas mais significativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['pf_pj', 'contratado_ofertas_simples', 'utilizado_ofertas_simples',\n",
    "         'leads_form', 'equipe', 'utilizado_destaque', 'valor_mensal',\n",
    "         'quantidade_mes', 'status_pagamento', 'churn', 'regiao', 'oficina', 'tipo_de_plano', 'frequencia_de_faturamento']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['status_pagamento'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "TRAIN: [ 7068  7069  7070 ... 35335 35336 35337] TEST: [   0    1    2 ... 7065 7066 7067]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([ 7068,  7069,  7070,  7071,  7072,  7073,  7074,  7075,  7076,\\n             7077,\\n            ...\\n            35328, 35329, 35330, 35331, 35332, 35333, 35334, 35335, 35336,\\n            35337],\\n           dtype='int64', length=28270)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13508/3672431361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m  \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TRAIN:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TEST:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m  \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m  \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1372\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([ 7068,  7069,  7070,  7071,  7072,  7073,  7074,  7075,  7076,\\n             7077,\\n            ...\\n            35328, 35329, 35330, 35331, 35332, 35333, 35334, 35335, 35336,\\n            35337],\\n           dtype='int64', length=28270)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "X = df.drop(['churn'], axis=1)\n",
    "y = df['churn'].astype(int)\n",
    "\n",
    "# kf = KFold(n_splits=5) # Define the split - into 2 folds \n",
    "# kf.get_n_splits(X)\n",
    "# print(kf) \n",
    "\n",
    "# for train_index, test_index in kf.split(X):\n",
    " # print('TRAIN:', train_index, 'TEST:', test_index)\n",
    " # X_train, X_test = X[train_index], X[test_index]\n",
    " # y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação do Smote (VERIFICAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "# X_train, y_train = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['contratado_ofertas_simples', 'utilizado_ofertas_simples',\n",
    "                    'leads_form', 'utilizado_destaque', 'valor_mensal', 'quantidade_mes']\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    ")\n",
    "\n",
    "categorical_features = ['pf_pj', 'equipe', 'status_pagamento',\n",
    "                        'regiao', 'oficina', 'tipo_de_plano', 'frequencia_de_faturamento']\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"onehot\", OneHotEncoder(handle_unknown='ignore')),\n",
    "           (\"imputer\", SimpleImputer(strategy=\"constant\"))]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        ('smote', SMOTE(random_state=0, sampling_strategy=0.75)),\n",
    "        (\"classifier\", MLPClassifier(hidden_layer_sizes=(100, 300),\n",
    "                      random_state=1,\n",
    "                      learning_rate_init=0.01, solver='adam', activation='relu'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"onehot\", LeaveOneOutEncoder()),\n",
    "#         (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "#         (\"scaler\", RobustScaler(with_centering=False)),\n",
    "#         ('smote', SMOTE(random_state=0)),\n",
    "#         (\"classifier\", MLPClassifier(hidden_layer_sizes=(6, 5),\n",
    "#                                      random_state=1,\n",
    "#                                      learning_rate_init=0.01))\n",
    "#     ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01, 'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoramento (ml flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('Churn Prediction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registro da signature e do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = infer_signature(X_test, y_pred)\n",
    "mlflow.sklearn.log_model(pipeline, 'model_pipeline', signature=signature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registro dos Parâmetros do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pipeline.named_steps[\"classifier\"].get_params()\n",
    "mlflow.log_params(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registro da matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(pipeline, X_test, y_test, display_labels=[\n",
    "    \"positivo\", \"negativo\"], values_format=\"d\")\n",
    "\n",
    "plt.savefig(\"mlruns/atual_model_confusion_matrix_.png\")\n",
    "mlflow.log_artifact(\"mlruns/atual_model_confusion_matrix_.png\")\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registro de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = round(f1_score(y_test, y_pred, average='macro')*100, 2)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "precision = round(precision_score(y_test, y_pred)*100, 2)\n",
    "recall = round(recall_score(y_test, y_pred)*100, 2)\n",
    "\n",
    "mlflow.log_metric(\"f1\", f1)\n",
    "mlflow.log_metric(\"accuracy\", accuracy)\n",
    "mlflow.log_metric(\"precision\", precision)\n",
    "mlflow.log_metric(\"recall\", recall)\n",
    "\n",
    "print(\"f1: \", f1)\n",
    "print(\"accuracy:\", accuracy)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalização do experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "solver = ['lbfgs', 'sgd', 'adam']\n",
    "learning_rate = [0.01, 0.0001, 0.1]\n",
    "hidden_layer_sizes = [(100,),(500,)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters2 = {'activation': activation,\n",
    "              'solver': solver,\n",
    "              'learning_rate_init': learning_rate,\n",
    "              'hidden_layer_sizes': hidden_layer_sizes,\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"scaler\", Normalizer()),\n",
    "        ('smote', SMOTE(random_state=0)),\n",
    "        ('gridsearch', GridSearchCV(MLPClassifier(), param_grid=parameters2))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search = GridSearchCV(MLPClassifier(), param_grid=parameters)\n",
    "# grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline2.fit(X_train, y_train)\n",
    "# print(pipeline2.best_params_)\n",
    "# print(pipeline2.best_estimator_)\n",
    "# params2 = pipeline2.named_steps[\"gridsearch\"].best_params_\n",
    "# print(params2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60683c818ea6f768f811ad5f90736ebd9ed15f5ee0114937570dcd60c186bf40"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
